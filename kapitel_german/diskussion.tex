\newpage
\section{Diskussion}\label{sec:diskussion}

Die vorliegende Arbeit hat systematisch untersucht, wie ein multimodales Diffusionsmodell ressourceneffizient auf die Generierung minimalistischer Logos spezialisiert werden kann. Durch die Kombination von \ac{LoRA}-basiertem Feintuning und ControlNet-gesteuerter Bildgenerierung wurde ein Prototyp entwickelt, der sowohl textuelle als auch strukturelle Vorgaben verarbeiten kann. In diesem Kapitel werden die gewonnenen Erkenntnisse in den Kontext der wissenschaftlichen Literatur eingeordnet, methodische Limitationen kritisch reflektiert und praktische sowie wissenschaftliche Implikationen diskutiert.

\subsection{Interpretation der Ergebnisse}

Die Interpretation der Ergebnisse erfolgt im Kontext der experimentellen Methodik dieser Arbeit, die auf der systematischen Variation von Hyperparametern unter kontrollierten Bedingungen basiert. Wie in Kapitel~\ref{sec:einleitung} dargelegt, bildet das Experiment als wissenschaftliches Verfahren den Kern der Erkenntnisgewinnung: Durch gezielte Veränderungen der Modellkonfiguration wurden deren Auswirkungen auf die Ergebnisqualität quantifiziert und anhand etablierter Metriken bewertet. Diese experimentelle Herangehensweise ermöglicht es, kausale Zusammenhänge zwischen Hyperparameter-Konfigurationen und Modellperformance zu identifizieren und die aufgestellten Hypothesen systematisch zu überprüfen.

\subsubsection{Bestätigung der Hypothesen}

Die \textbf{Hypothese H1}, die besagt, dass die zusätzliche Konditionierung durch eine Skizze zu einer signifikant höheren strukturellen Übereinstimmung führt, konnte eindeutig bestätigt werden. Die Evaluation zeigte einen dramatischen Anstieg des \ac{SSIM}-Scores von 0,617 beim Basismodell ohne ControlNet auf 0,817 beim Basismodell mit ControlNet (+32,4\,\%). Diese erhebliche Verbesserung validiert die theoretischen Überlegungen von \textcite{ZHANG2023}, die ControlNet als Lösung für die bekannte Schwäche rein textkonditionierter Modelle entwickelten, geometrische und kompositorische Anforderungen präzise zu erfüllen.


\textbf{Hypothese H2}, die eine Qualitätsverbesserung durch domänenspezifisches Feintuning postuliert, wurde vollständig bestätigt: Das beste feinabgestimmte Modell erreichte einen \ac{CLIP}-Score von 0,284 gegenüber 0,274 beim Basismodell (+3,7\,\%) sowie eine \ac{FID}-Reduktion von 229,0 auf 158,2 (-30,9\,\%). Diese Ergebnisse stehen im Einklang mit \textcite{ruiz2023dreamboothfinetuningtexttoimage}, die bereits mit 1.000 Trainingsiterationen signifikante Qualitätsverbesserungen nachwiesen. Die verwendeten 2.534 Trainingsschritte orientieren sich an \textcite{cloneofsimo_lora} und erwiesen sich als ausreichend für stabiles Konvergenzniveau. Interessanterweise erreichte das untrainierte Basismodell bei der Strukturtreue (\ac{SSIM}) mit 0,817 einen höheren Wert als das feinabgestimmte Modell (0,789). Dieser leichte Rückgang wertet die Qualität nicht ab, sondern reflektiert eine gewollte gestalterische Freiheit: Das Feintuning verschiebt den Fokus von reiner Strukturtreue hin zu semantischer Akkuratesse und visueller Qualität – ein erwünschter Trade-off, da minimalistische Logos nicht nur formgetreu, sondern vor allem inhaltlich und ästhetisch überzeugend sein müssen.


Die \textbf{Hypothese H3}, die eine Korrelation zwischen Hyperparameter-Konfiguration und Ergebnisqualität annimmt, wurde ebenfalls bestätigt. Die Lernrate erwies sich als dominantester Faktor sowohl für die semantische Kohärenz (\ac{CLIP}) als auch für die visuelle Qualität (\ac{FID}). Eine hohe Lernrate von $1e-4$ in Kombination mit der ``extended''-Konfiguration, die sowohl Attention- als auch Feed-Forward-Layer adaptiert, führte zu den besten Gesamtergebnissen. Der \ac{LoRA}-Rang zeigte einen moderateren Einfluss, wobei höhere Ränge (32) bei hohen Lernraten tendenziell bessere semantische Kohärenz ermöglichten. Diese Beobachtung deckt sich mit der theoretischen Überlegung von \textcite[S. 4]{HU2021}, dass sich das Training mit \ac{LoRA} bei steigendem Rang dem eines vollständigen Feintunings annähert, wodurch eine größere Modellkapazität zur Erfassung komplexer, domänenspezifischer Muster entsteht.


Die Überprüfung von \textbf{Hypothese H4}, die eine Überlegenheit des optimierten Prototyps in der qualitativen Nutzerbewertung annimmt, erfolgte durch eine Kombination aus stilistischer Analyse mit objektivem Fokus und einer subjektiven Onlinebefragung. Die stilistische Bewertung der Fallbeispiele (siehe Kapitel \ref{sec:objective_logo_gen_analysis}) offenbarte klare qualitative Vorteile des feinabgestimmten Modells, etwa bei der zuverlässigen Umsetzung von Anweisungen wie einem einfarbigen Hintergrund (\textit{solid background}) und der Verwendung stimmiger Farbpaletten im minimalistischen Stil. Gleichzeitig wurden aber auch Schwächen bei der feingranularen Umsetzung von Details wie Schriftarten oder spezifischen Attributen wie Farbverläufen deutlich.
Die subjektive Evaluation mittels Onlinebefragung mit 47 Teilnehmenden lieferte ein ergänzendes, aber differenziertes Bild: Das feinabgestimmte Modell wurde in 52,1\,\% aller Bewertungen präferiert (245 von 470), jedoch ohne statistische Signifikanz (p=0,3808). Trotz der ausbleibenden Signifikanz deutet die konsistente, leichte Präferenz in beiden Dimensionen (Optik: 51,5\,\%, Kommerziell: 52,8\,\%) darauf hin, dass das feinabgestimmte Modell die Nutzerakzeptanz tendenziell erhöht. Bemerkenswert ist die deutliche Präferenz bei Fallbeispiel F4 (89,4\,\%), einem Monogramm basierend auf einer handgezeichneten Skizze. Dies legt nahe, dass die wahrgenommenen qualitativen Verbesserungen des Modells, insbesondere bei der Interpretation authentischer, menschlicher Eingaben, das Gewicht der verbleibenden kleineren Mängel übersteigen.

\subsubsection{Validität der Ergebnisse}

\paragraph*{Interne Validität}
Die Reproduzierbarkeit wurde durch die Verwendung eines festen Seeds (42), die Versionierung aller Abhängigkeiten und das systematische Tracking mittels MLflow sichergestellt. Die konsistente Trainings- und Evaluierungsumgebung minimiert konfundierende Variablen. Die Aufteilung in Trainings-, Validierungs- und Testdatensatz folgt bewährten Praktiken und verhindert Data-Leakage. Die einmalige Evaluation auf dem Testdatensatz erst nach Modellauswahl reduziert das Risiko von Overfitting auf die Evaluierungsmetriken.

\paragraph*{Externe Validität}
Die Generalisierbarkeit der Ergebnisse ist durch die spezifische Domäne (minimalistische Logos), das gewählte Basismodell (Stable Diffusion v1.5) und die Hardware-Konfiguration begrenzt. Neuere Modellversionen (z. B. \acs{SDXL} \parencite{podell2023sdxlimprovinglatentdiffusion}) könnten andere Optimierungsdynamiken aufweisen. Die Übertragbarkeit auf andere Diffusionsmodelle wie DALL-E \parencite{RAMESH2022} oder Imagen \parencite{saharia2022photorealistictexttoimagediffusionmodels} ist nicht ohne weiteres gegeben.

\paragraph*{Ökologische Validität}
Die praktische Anwendbarkeit wurde durch die qualitative Befragung mit realen Nutzenden ansatzweise validiert. Die Verblindung der Logos verhinderte Verzerrungen durch Erwartungseffekte. Allerdings wurde die Integration in einen realen Designworkflow nicht getestet. Aspekte wie die Benutzerfreundlichkeit der Prompt-Formulierung, die Anzahl benötigter Iterationen bis zum zufriedenstellenden Ergebnis oder die tatsächliche Zeitersparnis gegenüber traditionellen Designprozessen blieben ungeklärt.

\subsection{Limitationen und Implikationen}\label{sec:limitations_and_implications}

\subsubsection{Methodische Einschränkungen}

Im Sinne der \acs{TDSP}-Methodik (\acl{TDSP}) von \textcite{tdsp_article}, die dieser Arbeit als strukturierendes Rahmenwerk diente, werden im Folgenden die identifizierten Limitationen entlang der \acs{TDSP}-Phasen diskutiert. Dabei werden bewusst Implikationen in Form von Feedbackschleifen reflektiert: Die Einschränkungen in den Phasen der Datenbeschaffung, Datenaufbereitung und Modellierung werden als Ansatzpunkte für iterative Verbesserungen verstanden, um die kontinuierliche Optimierung des entwickelten Systems zu ermöglichen. Für jede Phase werden konkrete Verbesserungsansätze abgeleitet, die in zukünftigen Iterationen umgesetzt werden könnten.

\paragraph*{Datenbasis und Generalisierbarkeit (\acs{TDSP}-Phase: Datenbeschaffung)}
Die Arbeit basiert auf dem Datensatz \textit{iamkaikai/amazing\_logos\_v4} von \textcite{iamkaikai_amazing_logos_v4}, der ca. 400.000 Logos umfasst. Obwohl dieser Datensatz umfangreich und vielfältig ist, repräsentiert er eine spezifische Stichprobe minimalistischer und abstrakter Logos. Die Generalisierbarkeit der Ergebnisse auf andere Logo-Stile (z. B. detailreiche, fotorealistische oder handgezeichnete Logos) ist daher eingeschränkt. Zudem wurden die Logos auf eine kleinere Teilmenge reduziert, um die Trainingszeit auf handelsüblicher Hardware zu optimieren.

\textbf{Feedbackschleife:} Eine iterative Verbesserung könnte durch das Akquirieren weiterer hochqualitativer Datensätze erfolgen. Zudem könnten Logos mittels Human Labeling oder KI nach optischer Qualität gelabelt werden, um nur die besten für das weitere Training zu verwenden.

\paragraph*{Caption-Qualität (\acs{TDSP}-Phase: Datenaufbereitung)}
Die im Datensatz enthaltenen Captions folgen nach der Aufbereitung einem strukturierten Schema (\texttt{<Überschrift>; <Beschreibung>; [Tags]}), weisen jedoch systematische Qualitätsprobleme auf: Die Beschreibungen bestehen häufig nur aus wenigen Schlagwörtern, und die Tags zeigen geringe Variation, wobei bestimmte Tags in nahezu jedem Beispiel auftreten. Wie \textcite{gualortí2025future} betonen, ist die präzise textuelle Beschreibung von Designelementen eine zentrale Herausforderung für Text-zu-Bild-Modelle.

\textbf{Feedbackschleife:} Eine deutliche Qualitätsverbesserung könnte durch den Einsatz eines \acs{VLM} (\acl{VLM}) erreicht werden, das zwei zentrale Aufgaben übernimmt: Erstens die automatisierte Neugenerierung detaillierter und präziser Logo-Beschreibungen anstelle von stark vereinfachten Schlagwort-Beschreibungen. Wie \textcite{zeng-etal-2025-enhancing-large} zeigen, sind hochwertige Bildunterschriften essenziell für die Verbesserung der modalen Ausrichtung und des visuellen Verständnisses in multimodalen Modellen; ultra-detaillierte Captions verbessern deren Wahrnehmungs- und kognitive Fähigkeiten signifikant über mehrere Vision-Language-Benchmarks hinweg. Zweitens eine systematische Kategorisierung der Logos nach den in Kapitel~\ref{subsubsec:die_topologie_der_marken_klassifikation_minimalistischer_logotypen} beschriebenen Typologien (Typografische Logos: Wortmarken, Buchstabenformen; Bildmarken: Embleme, Piktoriale Marken, Abstrakte Marken; Kombinierte Logos), um dem Modell strukturierte Stil-Information zu liefern. Ein stichprobenartiges manuelles Review der automatisch generierten Beschreibungen und Kategorisierungen durch menschliche Experten könnte zudem die Qualität validieren und als Grundlage für weitere Verfeinerungen dienen.

\paragraph*{Skizzengenerierung (\acs{TDSP}-Phase: Datenaufbereitung)}
Die Entscheidung, Skizzen mittels Stable Diffusion v1.5 mit ControlNet zu generieren anstatt ein spezialisiertes externes Modell zu nutzen, war primär kostengetrieben. Während dieser Ansatz praktikabel und ressourceneffizient ist, könnte die Qualität der generierten Skizzen hinter der eines dedizierten Photo-to-Sketch-Modells zurückbleiben. Die Verwendung von Scribble-Maps als Zwischenschritt führt zu einer gewissen Abstraktion, die zwar für minimalistische Logos vorteilhaft sein kann, aber auch Details verloren gehen lässt.

\textbf{Feedbackschleife:} Eine systematische A/B-Evaluation verschiedener Skizzengenerierungsansätze (z. B. Canny-Edge-Detection, dedizierte Sketch-Modelle, verschiedene ControlNet-Typen) könnte Aufschluss über das Optimierungspotenzial geben. Darüber hinaus bietet die Skizzengenerierung erhebliches Potenzial für Data Augmentation: Die Kombination mehrerer Generierungsmethoden im Trainingsprozess könnte die Robustheit und Generalisierbarkeit des Modells signifikant erhöhen. Durch die Exposition gegenüber unterschiedlichen Skizzenstilen und Abstraktionsgraden würde das Modell lernen, mit einer größeren Bandbreite struktureller Vorgaben umzugehen, was die Anwendbarkeit in realen Designszenarien verbessern könnte.

\paragraph*{Hyperparameter-Exploration und Trainingsinstabilität (\acs{TDSP}-Phase: Modellierung)}
Die systematische Evaluation von 20 Hyperparameter-Konfigurationen offenbarte komplexe Interaktionseffekte zwischen Lernrate, \ac{LoRA}-Rang und Zielmodul-Konfiguration. Generell erwiesen sich hohe Lernraten als vorteilhaft für die Modellperformance. Bei ``attn\_only'' zeigte sich eine stabilere Konvergenz in späteren Epochen (ab Epoche 9). Überraschend ist die Beobachtung bei ``extended'' mit der Konfiguration $r=32, lr=1e-6$: Ab Epoche 14 näherte sich diese niedrige Lernrate deutlich an die Leistung von $1e-4$ an, was das Potenzial von Lernraten-Scheduling andeutet. Der begrenzte Suchraum ($r \in [4,32]$, nur zwei Zielmodul-Konfigurationen) lässt jedoch Raum für weitere Optimierung, etwa durch gewichtete U-Net/Text-Encoder-Mischungen \parencite{cloneofsimo_lora}.

Ein charakteristisches Merkmal war die hohe Variabilität der Validierungsverlustkurven, besonders bei der ``extended'' Konfiguration. Diese Instabilität ist bei \ac{LoRA} in Diffusionsmodellen dokumentiert \parencite{luo2024privacypreservinglowrankadaptationmembership}. Wie \textcite{hayou2024impactinitializationlorafinetuning} zeigen, ermöglicht das standardmäßige Init[A]-Schema (Matrix A zufällig initialisiert, Matrix B auf Null gesetzt) zwar die Verwendung größerer Lernraten und führt dadurch zu effizienteren Lernprozessen, erzeugt jedoch gleichzeitig eine höhere Ausgabeinstabilität während des Trainings. Diese scheinbar nachteilige Variabilität ist paradoxerweise Teil eines produktiven Lernprozesses, da sie effizienteres Feature Learning ermöglicht.

\textbf{Feedbackschleife:} Automatisierte Verfahren wie Bayesian Optimization über einen erweiterten Parameterraum sowie die Evaluation alternativer Initialisierungsschemata und Stabilisierungstechniken (SMP-LoRA \parencite{hayou2024impactinitializationlorafinetuning}) könnten in einer nächsten Iteration implementiert werden. Adaptives Early Stopping und Lernraten-Scheduling versprechen robustere Konvergenz bei gleichbleibender Qualität.

\subsubsection{Technische Limitationen}

Die technischen Einschränkungen betreffen primär die \acs{TDSP}-Phase der Modellierung und bieten konkrete Ansatzpunkte für Performance-Optimierungen in zukünftigen Iterationen.

\paragraph*{Hardware-Beschränkungen (\acs{TDSP}-Phase: Modellierung)}
Die Arbeit wurde bewusst auf handelsüblicher Hardware (NVIDIA RTX 5080 mit 16 GB \acs{VRAM}) durchgeführt, um die praktische Anwendbarkeit zu demonstrieren. Diese Entscheidung brachte jedoch Einschränkungen mit sich: Die Batch-Größe musste auf 8 begrenzt werden, was die Trainingseffizienz reduziert und potenziell zu instabileren Gradientenschätzungen führt. Größere Batch-Größen könnten stabilere und schnellere Konvergenz ermöglichen.

\textbf{Feedbackschleife:} Die Implementierung von \ac{QLoRA} \parencite{dettmers2023qloraefficientfinetuningquantized} mit 4-Bit-Quantisierung könnte den Speicherbedarf drastisch reduzieren und größere Batch-Größen ermöglichen, ohne auf leistungsstärkere Hardware angewiesen zu sein. Ebenso könnte \texttt{torch.compile()} \parencite{wen2023torchcompile} für signifikante Geschwindigkeitssteigerungen sorgen. Diese Optimierungen könnten in einer nächsten Trainingsiteration evaluiert werden, wobei die Auswirkungen auf Trainingsgeschwindigkeit und Modellqualität systematisch gemessen werden.

\paragraph*{Evaluierungsmetriken (\acs{TDSP}-Phase: Modellierung/Deployment)}
Die gewählten Metriken – \ac{CLIP}-Score, \ac{SSIM} und \ac{FID} – sind etablierte Standards in der Bildgenerierungsforschung, haben jedoch inhärente Limitationen. Der \ac{CLIP}-Score misst semantische Übereinstimmung auf Basis multimodaler Embeddings, kann aber kulturelle oder domänenspezifische Nuancen übersehen. Der \ac{SSIM} fokussiert auf strukturelle Ähnlichkeit, erfasst jedoch keine semantischen oder ästhetischen Aspekte. Der \ac{FID} vergleicht Merkmalsverteilungen, ist aber sensitiv gegenüber der Auswahl des Referenzdatensatzes und kann bei kleinen Stichproben instabil sein.

Speziell für Logo-Design relevante Aspekte wie Markenkonformität, Skalierbarkeit über verschiedene Medien oder rechtliche Unbedenklichkeit wurden nicht quantitativ gemessen. Die qualitative Befragung mit 47 Teilnehmenden bietet wertvolle Einblicke, konnte jedoch aufgrund der leichten und statistisch nicht signifikanten Präferenzen (Gesamt: 52,1\,\%, Optik: 51,5\,\%, Kommerziell: 52,8\,\%) keine eindeutige Überlegenheit des feinabgestimmten Modells nachweisen. Die wahrgenommenen Unterschiede zwischen den Modellen waren zu gering, um bei dieser Stichprobengröße statistische Signifikanz zu erreichen.

\textbf{Feedbackschleife:} Eine erweiterte Evaluation könnte domänenspezifische Metriken entwickeln, die Logo-spezifische Qualitätskriterien nach \textcite{Wheeler2017} (Einfachheit, Einprägsamkeit; vgl. Kapitel \ref{subsubsec:prinzipien_und_kriterien}) quantitativ erfassen. Zudem könnte eine größere qualitative Studie mit Designprofis robustere statistische Aussagen ermöglichen. Ein automatisierter Markenähnlichkeitscheck könnte als zusätzliche Metrik in die Evaluierungspipeline integriert werden.
